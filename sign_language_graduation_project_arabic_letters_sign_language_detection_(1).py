# -*- coding: utf-8 -*-
"""SIGN-LANGUAGE-GRADUATION-PROJECT-arabic-letters-sign-language-detection (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13zfN7ONI__vKGbQE9oVG7NHsjD_c6QOL

# Important Libraries
"""

import os
import numpy as np
import seaborn as sns
import librosa
import shutil
from io import BytesIO
from PIL import Image, ImageOps
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from sklearn.metrics import confusion_matrix, classification_report
from tensorflow.keras.optimizers import Adam

from PIL import ImageFile

# Allow loading of truncated images in PIL.
# This can be useful when dealing with incomplete image files.

ImageFile.LOAD_TRUNCATED_IMAGES = True

data_path = '/kaggle/input/rgb-arabic-alphabets-sign-language-dataset/RGB ArSL dataset'
data = []   # List to store image data
labels = []  # List to store labels
categories = os.listdir(data_path) # List of categories in this dataset
for category in categories:
    category_path = os.path.join(data_path, category) # Full path to the category directory
    # Loop over each image in the category
    for img_name in os.listdir(category_path):
        img_path = os.path.join(category_path, img_name) # Full path to the image file
        img = load_img(img_path, target_size=(224, 224))  # Load and resize the image
        img_array = img_to_array(img) # Convert image to a NumPy array
        img_array /= 255.0  # Normalize pixel values to [0,1]
        data.append(img_array)  # Add image array to the data list
        # Add category (label) to the labels list
        labels.append(category)

label_encoder = LabelEncoder()
encoded_labels = label_encoder.fit_transform(labels)
categorical_labels = to_categorical(encoded_labels)

label_encoder = LabelEncoder()
encoded_label = label_encoder.fit_transform(labels)
categorical_labels = to_categorical(encoded_label)
X_train, X_test, y_train, y_test = train_test_split(data, categorical_labels, test_size=0.2, random_state=42)
X_test,X_val,y_test,y_val=train_test_split(X_test,y_test,test_size=0.5, random_state=42)
X_train = np.array(X_train)
X_val = np.array(X_val)
X_test = np.array(X_test)
y_train = np.array(y_train)
y_val = np.array(y_val)
y_test = np.array(y_test)
print(f'X_train shape is {X_train.shape}')
print(f'X_val shape is {X_val.shape}')
print(f'X_test shape is {X_test.shape}')
print(f'y_train shape is {y_train.shape}')
print(f'y_val shape is {y_val.shape}')
print(f'y_test shape is {y_test.shape}')

import tensorflow as tf
from tensorflow.keras.applications import MobileNet
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import Adam
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report

input_shape = (224, 224, 3)
num_classes = 31

base_model = MobileNet(weights='imagenet', include_top=False, input_shape=input_shape)

model = Sequential([
    base_model,
    Flatten(),
    Dense(128,activation='relu'),
    Dense(64,activation='relu'),
    Dense(32,activation='relu'),
    Dense(num_classes, activation='softmax')
])

optimizer = Adam(learning_rate=0.001)
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

# Define callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
print(model.summary())
# Train the model
history = model.fit(
    X_train,
    y_train,
    batch_size=32,
    epochs=100,
    validation_data=(X_val, y_val),
    callbacks=[early_stopping],
    verbose=1
)

# Evaluate the model on test data
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f'Test Accuracy: {test_accuracy * 100:.2f}%')

# Make predictions
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true_classes = np.argmax(y_test, axis=1)

# Generate confusion matrix and visualize
conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# Print classification report
print('\nClassification Report:')
print(classification_report(y_true_classes, y_pred_classes, target_names=categories))

import numpy as np
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.preprocessing import LabelEncoder
import os

# Assuming your dataset path is still available
data_path = '/kaggle/input/rgb-arabic-alphabets-sign-language-dataset/RGB ArSL dataset'

# Load the label encoder used during training
label_encoder = LabelEncoder()
categories = os.listdir(data_path)
label_encoder.fit(categories)

def predict_image(image_path, model, label_encoder):
    # Load and preprocess the image
    img = load_img(image_path, target_size=(224, 224))  # Resize to match model's input size
    img_array = img_to_array(img)  # Convert to array
    img_array = img_array / 255.0  # Normalize to [0,1]
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension

    # Make a prediction
    predictions = model.predict(img_array)
    predicted_class_index = np.argmax(predictions)

    # Decode the prediction to the corresponding label
    predicted_label = label_encoder.inverse_transform([predicted_class_index])[0]

    return predicted_label

# Path to the image you want to test
test_image_path = '/kaggle/input/rgb-arabic-alphabets-sign-language-dataset/RGB ArSL dataset/Ain/Ain_0.jpg'

# Predict the label using the trained model
predicted_label = predict_image(test_image_path, model, label_encoder)

print(f"The predicted label for the image is: {predicted_label}")

